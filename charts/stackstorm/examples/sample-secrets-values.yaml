image:
  # Image pull policy
  pullPolicy: IfNotPresent
  repository: ""
  tag: "3.5"

serviceAccount:
  # Whether the Chart should create the service account or not
  create: true
  # Used to define service account annotations
  serviceAccountAnnotations: {}
  # Used to override service account name
  serviceAccountName:

ingress:
  enabled: true
  className: "nginx"
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/proxy-read-timeout: '86400'
    nginx.ingress.kubernetes.io/proxy-send-timeout: '86400'
    nginx.ingress.kubernetes.io/use-regex: "true"
    cert-manager.io/cluster-issuer: letsencrypt-prod
    external-dns.alpha.kubernetes.io/alias: "true"
  hosts:
    - host: stackstorm.example.com
      paths:
        - path: /
          pathType: ImplementationSpecific
          serviceName: stackstorm-st2web
          servicePort: 80
  tls:
    - secretName: "stackstorm-tls"
      hosts:
        - stackstorm.example.com
##
## StackStorm shared variables
##
st2:
  # username: administrator
  ## Note: The helm chart will auto-generate this value if not supplied here.
  ## Having this here is not ideal, but at least allows us to know the password.
  # password: crucible

  # existingConfigSecret contains the administrator credentials under these keys
  # ST2_AUTH_USERNAME: 
  # ST2_AUTH_PASSWORD:
  existingAuthSecret: test-stackstorm-auth-secret
  # existingConfigSecret contains the custom config, under the key: st2.secrets.conf
  existingConfigSecret: test-stackstorm-config-secret
  # existingPacksConfigSecret has the configurations for all needed packs as a secret with
  # keys for each config.yaml file
  existingPacksConfigSecret: test-stackstorm-pack-config-secret

  system_user:
    user: stanley
    # templating is allowed for this key
    ssh_key_file: "/home/{{ .Values.st2.system_user.user }}/.ssh/stanley_rsa"


## TODO - remove vmware creds secret. This will possibly
## require providing custom built packs as volumes in a pvc
## See: https://github.com/StackStorm/stackstorm-k8s?tab=readme-ov-file#method-2-shared-volumes
  packs:
    images:
      - repository: cmusei
        name: st2packs
        tag: 1.2.0
        pullPolicy: IfNotPresent

    # Could not get the file permissions to work and allow me to 
    # even start stackstorm with these volumes mounted
    # volumes:
    #   enabled: true
    #   packs_subpath: stackstorm/packdata/packs
    #   virtualenvs_subpath: stackstorm/packdata/virtualenvs
    #   configs_subpath: stackstorm/packdata/configs

    #   packs:
    #     persistentVolumeClaim:
    #       claimName: "appdata"

    #   virtualenvs:
    #     persistentVolumeClaim:
    #       claimName: "appdata"

    #   configs:
    #     persistentVolumeClaim:
    #       claimName: "appdata"

st2web:
  # Minimum 2 replicas are recommended to run st2web in HA mode
  replicas: 1
  # Tested resource consumption based on multiple requests to st2web within nginx
  # Please adjust based on your conscious choice
  resources:
    requests:
      memory: "25Mi"
      cpu: "50m"
    limits:
      memory: "100Mi"
  annotations: {}
  # Override default image settings (for now, only tag can be overridden)
  image:
    {}
    ## Note that Helm templating is supported in this block!
    #tag: "{{ .Values.image.tag }}"
  # TODO: Add Ingress setting as a way to expose service to public (#6).
  # ingress:
  service:
    # type can be one of "ClusterIP", "NodePort", "LoadBalancer" or "ExternalName"
    type: "ClusterIP"
    # The hostname associated with st2web service (externalName, added to external DNS, etc.)
    hostname: stackstorm.example.com
    annotations: {}
  nodeSelector:
    #kubernetes.io/hostname: $STACKSTORM_NODE

  config: |
    'use strict';

    /* global angular */
    angular.module('main')
      .constant('st2Config', {

        hosts: [
          {
            name: 'test',
            url: 'https://stackstorm.example.com/api',
            auth: 'https://stackstorm.example.com/auth',
            stream: 'https://stackstorm.example.com/stream',
          }
        ]
      });

st2auth:
  replicas: 1
  resources:
    requests:
      memory: "85Mi"
      cpu: "50m"
  nodeSelector:
    #kubernetes.io/hostname: $STACKSTORM_NODE

st2api:
  replicas: 1
  resources:
    requests:
      memory: "150Mi"
      cpu: "25m"
  nodeSelector:
    #kubernetes.io/hostname: $STACKSTORM_NODE

st2stream:
  replicas: 1
  resources:
    requests:
      memory: "100Mi"
      cpu: "50m"
  nodeSelector:
    #kubernetes.io/hostname: $STACKSTORM_NODE

st2rulesengine:
  replicas: 1
  resources:
    requests:
      memory: "75Mi"
      cpu: "25m"
  nodeSelector:
    #kubernetes.io/hostname: $STACKSTORM_NODE


st2timersengine:
  resources:
    requests:
      memory: "75Mi"
      cpu: "10m"
  nodeSelector:
    #kubernetes.io/hostname: $STACKSTORM_NODE

st2workflowengine:
  replicas: 1
  resources:
    requests:
      memory: "200Mi"
      cpu: "100m"
  nodeSelector:
    #kubernetes.io/hostname: $STACKSTORM_NODE

st2scheduler:
  replicas: 1
  resources:
    requests:
      memory: "75Mi"
      cpu: "50m"
  nodeSelector:
    #kubernetes.io/hostname: $STACKSTORM_NODE

st2notifier:
  replicas: 1
  resources:
    requests:
      memory: "75Mi"
      cpu: "50m"
  nodeSelector:
    #kubernetes.io/hostname: $STACKSTORM_NODE

st2actionrunner:
  replicas: 2
  resources:
    requests:
      memory: "200Mi"
      cpu: "75m"
  nodeSelector:
    #kubernetes.io/hostname: $STACKSTORM_NODE

st2sensorcontainer:
  resources:
    requests:
      memory: "100Mi"
      cpu: "50m"
  nodeSelector:
    #kubernetes.io/hostname: $STACKSTORM_NODE

st2client:
  # st2client config (~/.st2/config) template.
  # see: https://docs.stackstorm.com/reference/cli.html#configuration-file
  # You can access env variables here because this is used in a bash heredoc.
  # For example, you could use a var injected with envFromSecrets.
  # Note that Helm templating is supported in this block!
  envFromSecrets:
    - test-stackstorm-auth-secret

  st2clientConfig: |
    [credentials]
    username = ${ST2_AUTH_USERNAME}
    password = ${ST2_AUTH_PASSWORD}

  # extra_volumes: 
  #   - name: st2-extra-volume
  #     mount:
  #       mountPath: /opt/stackstorm/extra
  #       readOnly: false
  #       subPath: stackstorm
  #     volume:
  #       persistentVolumeClaim:
  #         claimName: "appdata"

st2garbagecollector:
  # Having 1 st2garbagecollector unique replica is enough for periodic task like st2 history garbage collection
  replicas: 1
  resources:
    requests:
      memory: "80Mi"
      cpu: "10m"
##
## Various batch jobs (apply-rbac-definitions, apikey-load, key-load, register-content)
##
jobs:
  # st2client config (~/.st2/config) template for jobs that need it.
  # see: https://docs.stackstorm.com/reference/cli.html#configuration-file
  # You can access env variables here because this is used in a bash heredoc.
  # For example, you could use a var injected with envFromSecrets.
  # Note that Helm templating is supported in this block!
  envFromSecrets: 
    - test-stackstorm-auth-secret

  st2clientConfig: |
    [credentials]
    username = ${ST2_AUTH_USERNAME}
    password = ${ST2_AUTH_PASSWORD}

mongodb:
  enabled: true

  service:
    type: ClusterIP
    port: 27017
    portName: mongodb

  architecture: standalone  

  image:
    registry: docker.io
    repository: bitnami/mongodb
    tag: 7.0.5-debian-11-r6
    pullPolicy: IfNotPresent
    pullSecrets: []
    debug: false

  auth:
    enabled: true
    existingSecret: test-mongodb-secret
    rootUser: mongo
    usernames:
      - administrator
    databases:
      - st2

  persistence:
    enabled: true
    existingClaim: "appdata"
    subPath: stackstorm/mongodb

  # Note: There is a bug in the current mongodb bitnami helm chart
  # that incorrectly sets the volumePermissions, which is why
  # we are including an initContainer for this below
  volumePermissions:
    enabled: false

  initContainers:
    - args:
      - |
        mkdir -p /bitnami/mongodb
        chown -R "1001:1001" "/bitnami/mongodb"
      command:
      - /bin/bash
      - -ec
      image: docker.io/bitnami/minideb:buster
      imagePullPolicy: Always
      name: volume-permissions
      resources: {}
      securityContext:
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /bitnami/mongodb
        name: datadir
        subPath: stackstorm/mongodb

rabbitmq:
  enabled: true

  # service:
    # nameOverride: stackstorm-rabbitmq

  clustering:
    # On unclean cluster restarts forceBoot is required to cleanup Mnesia tables (see: https://github.com/helm/charts/issues/13485)
    # Use it only if you prefer availability over integrity.
    forceBoot: true
  # Authentication Details
  auth:
    username: administrator
    existingPasswordSecret: test-rabbitmq-secret
    existingErlangSecret: test-rabbitmq-secret

  # RabbitMQ Memory high watermark. See: http://www.rabbitmq.com/memory.html
  # Default values might not be enough for StackStorm deployment to work properly. We recommend to adjust these settings for you needs as well as enable Pod memory limits via "resources".
  #rabbitmqMemoryHighWatermark: 512MB
  #rabbitmqMemoryHighWatermarkType: absolute
  persistence:
    enabled: true
    existingClaim: appdata
    subPath: stackstorm/rabbitmq

  volumePermissions:
    enabled: true
  # We recommend to set the memory limit for RabbitMQ-HA Pods in production deployments.
  # Make sure to also change the rabbitmqMemoryHighWatermark following the formula:
  # rabbitmqMemoryHighWatermark = 0.4 * resources.limits.memory
  resources: {}
  # number of replicas in the rabbit cluster
  replicaCount: 1
  # As RabbitMQ enabled prometheus operator monitoring by default, disable it for non-prometheus users
  metrics:
    enabled: false

external-dns:
  enabled: false

redis:
  enabled: false